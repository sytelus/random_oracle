{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéØ Verbalized Sampling: Complete Framework Demo\n",
    "\n",
    "## Introduction\n",
    "\n",
    "**Ask for a distribution, not a sample.**\n",
    "\n",
    "This notebook demonstrates the complete `verbalized-sampling` framework. Instead of asking an LLM for one answer, we ask it for a small **distribution**‚Äî`k` candidates with **weights**‚Äîthen deterministically **filter ‚Üí normalize ‚Üí order**, and choose via **`dist.argmax()`** or **`dist.sample()`**.\n",
    "\n",
    "### What you'll learn:\n",
    "1. **Quick Start** - One-liner usage with `verbalize()`\n",
    "2. **Core API** - `DiscreteDist`, `Item`, selection methods\n",
    "3. **Transforms** - `map()`, `filter_items()`, `reweight()`\n",
    "4. **Practical Recipes** - Creative writing, QA, synthetic data\n",
    "5. **Advanced Features** - Weight modes, serialization, metadata inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Setup: Install and Import\n",
    "# !pip install verbalized-sampling\n",
    "\n",
    "import os\n",
    "from verbalized_sampling import verbalize, select, DiscreteDist, Item\n",
    "from IPython.display import display, Markdown\n",
    "import json\n",
    "\n",
    "# Set your API key (or use environment variables)\n",
    "os.environ[\"OPENAI_API_KEY\"] = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Quick Start (plan.md ¬ß0)\n",
    "\n",
    "The simplest way to use verbalized sampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning probability to 0\n",
      "Distribution definition: Randomly sample the responses from the full distribution.\n",
      "responses: [{'response': \"The morning Harold found the silver locket on his doorstep, he realized, too late, that yesterday's shadows had followed him home.\", 'probability': 0.22}, {'response': 'The clock struck midnight when the scream shattered the silence, echoing through the empty halls of Wrenwood Manor.', 'probability': 0.19}, {'response': 'No one noticed the missing painting at first, except for the one person who knew exactly why it had to disappear.', 'probability': 0.21}, {'response': 'As the sun melted into the horizon, Detective Marsh opened the letter that would unravel the quiet town‚Äôs darkest secret.', 'probability': 0.17}, {'response': 'They say the dead can‚Äôt speak, but the message scrawled in dust on the old piano begged to differ.', 'probability': 0.21}]\n",
      "# verbalized-sampling\n",
      "k=5  œÑ=0.12  Œ£p=1.000  model=gpt-4.1\n",
      "\n",
      "1. 0.220  \"The morning Harold found the silver locket on his doorstep, he realize...\"  []\n",
      "2. 0.210  \"No one noticed the missing painting at first, except for the one perso...\"  []\n",
      "3. 0.210  \"They say the dead can‚Äôt speak, but the message scrawled in dust on the...\"  []\n",
      "4. 0.190  \"The clock struck midnight when the scream shattered the silence, echoi...\"  []\n",
      "5. 0.170  \"As the sun melted into the horizon, Detective Marsh opened the letter ...\"  []\n",
      "\n",
      "Best (argmax): The morning Harold found the silver locket on his doorstep, he realized, too late, that yesterday's shadows had followed him home.\n",
      "\n",
      "Sampled (seed=7): No one noticed the missing painting at first, except for the one person who knew exactly why it had to disappear.\n"
     ]
    }
   ],
   "source": [
    "# Learn a tiny distribution from the model\n",
    "dist = verbalize(\n",
    "    \"Write an opening line for a mystery novel\",\n",
    "    k=5,\n",
    "    tau=0.12,\n",
    "    temperature=0.9,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "# Quick view of items & normalized masses\n",
    "print(dist.to_markdown())\n",
    "print()\n",
    "\n",
    "# Deterministic top item\n",
    "best = dist.argmax()\n",
    "print(f\"Best (argmax): {best.text}\")\n",
    "print()\n",
    "\n",
    "# Seeded weighted sample\n",
    "choice = dist.sample(seed=7)\n",
    "print(f\"Sampled (seed=7): {choice.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ Key Takeaway\n",
    "\n",
    "**What you get:** A `DiscreteDist[Item]` that's:\n",
    "- ‚úÖ **Auditable** - See all candidates with their weights\n",
    "- ‚úÖ **Serializable** - Save/load distributions\n",
    "- ‚úÖ **Composable** - Transform with `map()`, `filter()`, `reweight()`\n",
    "- ‚úÖ **Ergonomic** - Simple selection methods on the distribution itself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Core API: Understanding the Objects\n",
    "\n",
    "### 2.1 The `Item` Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item attributes:\n",
      "  text: The morning Harold found the silver locket on his doorstep, ...\n",
      "  p (normalized): 0.2200\n",
      "  meta keys: ['p_raw', 'p_clipped', 'repairs', 'idx_orig']\n",
      "\n",
      "Metadata details:\n",
      "  p_raw: 0.22\n",
      "  p_clipped: 0.22\n",
      "  repairs: []\n",
      "  idx_orig: 0\n"
     ]
    }
   ],
   "source": [
    "# Get the top item\n",
    "top_item = dist.argmax()\n",
    "\n",
    "print(\"Item attributes:\")\n",
    "print(f\"  text: {top_item.text[:60]}...\")\n",
    "print(f\"  p (normalized): {top_item.p:.4f}\")\n",
    "print(f\"  meta keys: {list(top_item.meta.keys())}\")\n",
    "print()\n",
    "\n",
    "# Inspect metadata\n",
    "print(\"Metadata details:\")\n",
    "print(f\"  p_raw: {top_item.meta.get('p_raw')}\")\n",
    "print(f\"  p_clipped: {top_item.meta.get('p_clipped')}\")\n",
    "print(f\"  repairs: {top_item.meta.get('repairs')}\")\n",
    "print(f\"  idx_orig: {top_item.meta.get('idx_orig')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 The `DiscreteDist` Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 5\n",
      "First item: The morning Harold found the silver lock...\n",
      "\n",
      "All items (descending by p):\n",
      "  1. p=0.220 - The morning Harold found the silver locket on his ...\n",
      "  2. p=0.210 - No one noticed the missing painting at first, exce...\n",
      "  3. p=0.210 - They say the dead can‚Äôt speak, but the message scr...\n",
      "  4. p=0.190 - The clock struck midnight when the scream shattere...\n",
      "  5. p=0.170 - As the sun melted into the horizon, Detective Mars...\n",
      "\n",
      "Probabilities: [0.22, 0.21, 0.21, 0.19, 0.17]\n",
      "Sum of probabilities: 1.000000\n"
     ]
    }
   ],
   "source": [
    "# DiscreteDist is a sequence\n",
    "print(f\"Length: {len(dist)}\")\n",
    "print(f\"First item: {dist[0].text[:40]}...\")\n",
    "print()\n",
    "\n",
    "# Access all items and probabilities\n",
    "print(\"All items (descending by p):\")\n",
    "for i, item in enumerate(dist, 1):\n",
    "    print(f\"  {i}. p={item.p:.3f} - {item.text[:50]}...\")\n",
    "print()\n",
    "\n",
    "# Get probability list\n",
    "print(f\"Probabilities: {[round(p, 3) for p in dist.p]}\")\n",
    "print(f\"Sum of probabilities: {sum(dist.p):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Trace Metadata\n",
    "\n",
    "Every distribution includes detailed trace information for debugging and auditing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trace metadata:\n",
      "  model: gpt-4.1\n",
      "  provider: openai\n",
      "  latency_ms: 4613.29984664917\n",
      "  k: 5\n",
      "  tau: 0.12\n",
      "  temperature: 0.9\n",
      "  seed: 42\n",
      "  use_strict_json: True\n",
      "  probability_definition: explicit\n",
      "  tau_relaxed: False\n",
      "  tau_final: 0.12\n",
      "  num_filtered: 0\n",
      "  weight_mode: elicited\n"
     ]
    }
   ],
   "source": [
    "print(\"Trace metadata:\")\n",
    "for key, value in dist.trace.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Selection Methods\n",
    "\n",
    "Two ways to select from a distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning probability to 0\n",
      "Distribution definition: Randomly sample the responses from the full distribution.\n",
      "responses: [{'response': 'Salutations, fellow traveler of the cosmos! May your journey today be filled with stardust and serendipity.', 'probability': 0.12}, {'response': 'Hey there, radiant soul! Ready to make some magic happen today?', 'probability': 0.18}, {'response': 'Greetings and jubilations! May your day shimmer with possibilities and cheerful surprises.', 'probability': 0.15}, {'response': 'Ahoy, adventurer! The universe just rolled out a red carpet for your arrival.', 'probability': 0.2}, {'response': 'Waves a wand‚ú® Hello and welcome! May your day unfold like a storybook of wonders.', 'probability': 0.13}]\n",
      "Direct methods:\n",
      "  argmax(): Ahoy, adventurer! The universe just rolled out a red carpet for your arrival.\n",
      "  sample(seed=42): Greetings and jubilations! May your day shimmer with possibilities and cheerful surprises.\n",
      "\n",
      "Using select() helper:\n",
      "  select(dist, 'argmax'): Ahoy, adventurer! The universe just rolled out a red carpet for your arrival.\n",
      "  select(dist, 'sample', seed=42): Greetings and jubilations! May your day shimmer with possibilities and cheerful surprises.\n",
      "\n",
      "Multiple samples (different seeds):\n",
      "  1. Ahoy, adventurer! The universe just rolled out a red carpet for your arrival.\n",
      "  2. Ahoy, adventurer! The universe just rolled out a red carpet for your arrival.\n",
      "  3. Waves a wand‚ú® Hello and welcome! May your day unfold like a storybook of wonders.\n",
      "  4. Ahoy, adventurer! The universe just rolled out a red carpet for your arrival.\n",
      "  5. Hey there, radiant soul! Ready to make some magic happen today?\n"
     ]
    }
   ],
   "source": [
    "dist = verbalize(\"Write a creative greeting\", k=5, temperature=0.8, seed=100)\n",
    "\n",
    "# Method 1: Direct methods on distribution\n",
    "best = dist.argmax()\n",
    "sampled = dist.sample(seed=42)\n",
    "\n",
    "print(\"Direct methods:\")\n",
    "print(f\"  argmax(): {best.text}\")\n",
    "print(f\"  sample(seed=42): {sampled.text}\")\n",
    "print()\n",
    "\n",
    "# Method 2: Using select() helper\n",
    "best2 = select(dist, strategy=\"argmax\")\n",
    "sampled2 = select(dist, strategy=\"sample\", seed=42)\n",
    "\n",
    "print(\"Using select() helper:\")\n",
    "print(f\"  select(dist, 'argmax'): {best2.text}\")\n",
    "print(f\"  select(dist, 'sample', seed=42): {sampled2.text}\")\n",
    "print()\n",
    "\n",
    "# Demonstrate sampling variability\n",
    "print(\"Multiple samples (different seeds):\")\n",
    "for i in range(5):\n",
    "    item = dist.sample(seed=200 + i)\n",
    "    print(f\"  {i+1}. {item.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Transforms: Functional Operations (plan.md ¬ß13.4)\n",
    "\n",
    "All transforms return new `DiscreteDist` objects and preserve invariants (Œ£p=1, descending order).\n",
    "\n",
    "### 4.1 `map()` - Transform text while preserving probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning probability to 0\n",
      "Distribution definition: Randomly sample the responses from the full distribution.\n",
      "responses: [{'response': 'Cerulean', 'probability': 0.14}, {'response': 'Mauve', 'probability': 0.11}, {'response': 'Amber', 'probability': 0.16}, {'response': 'Turquoise', 'probability': 0.17}, {'response': 'Chartreuse', 'probability': 0.09}]\n",
      "Original:\n",
      "  0.362 - Turquoise\n",
      "  0.340 - Amber\n",
      "  0.298 - Cerulean\n",
      "\n",
      "After map(uppercase):\n",
      "  0.362 - TURQUOISE\n",
      "  0.340 - AMBER\n",
      "  0.298 - CERULEAN\n",
      "\n",
      "After map(add prefix):\n",
      "  0.362 - Color: Turquoise\n",
      "  0.340 - Color: Amber\n",
      "  0.298 - Color: Cerulean\n"
     ]
    }
   ],
   "source": [
    "dist = verbalize(\"Write a color name\", k=5, temperature=0.8, seed=300)\n",
    "\n",
    "print(\"Original:\")\n",
    "for item in dist[:3]:\n",
    "    print(f\"  {item.p:.3f} - {item.text}\")\n",
    "print()\n",
    "\n",
    "# Transform: uppercase\n",
    "uppercased = dist.map(lambda it: it.text.upper())\n",
    "print(\"After map(uppercase):\")\n",
    "for item in uppercased[:3]:\n",
    "    print(f\"  {item.p:.3f} - {item.text}\")\n",
    "print()\n",
    "\n",
    "# Transform: add prefix\n",
    "prefixed = dist.map(lambda it: f\"Color: {it.text.strip()}\")\n",
    "print(\"After map(add prefix):\")\n",
    "for item in prefixed[:3]:\n",
    "    print(f\"  {item.p:.3f} - {item.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 `filter_items()` - Remove items and renormalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning probability to 0\n",
      "Distribution definition: Randomly sample the responses from the full distribution.\n",
      "responses: [{'response': 'AquaBliss', 'probability': 0.11}, {'response': 'ZenCharge', 'probability': 0.1}, {'response': 'SwiftSync', 'probability': 0.14}, {'response': 'GlowMate', 'probability': 0.13}, {'response': 'PureNest', 'probability': 0.09}, {'response': 'EcoScribe', 'probability': 0.12}, {'response': 'Lumeo', 'probability': 0.17}, {'response': 'SnapLink', 'probability': 0.14}]\n",
      "Original (5 items):\n",
      "  0.243 - Lumeo (length=5)\n",
      "  0.200 - SwiftSync (length=9)\n",
      "  0.200 - SnapLink (length=8)\n",
      "  0.186 - GlowMate (length=8)\n",
      "  0.171 - EcoScribe (length=9)\n",
      "\n",
      "After filter (length < 20): 5 items\n",
      "  0.243 - Lumeo\n",
      "  0.200 - SwiftSync\n",
      "  0.200 - SnapLink\n",
      "  0.186 - GlowMate\n",
      "  0.171 - EcoScribe\n",
      "\n",
      "Total probability after filter: 1.000000\n"
     ]
    }
   ],
   "source": [
    "dist = verbalize(\"Write a product name (1-2 words)\", k=8, temperature=0.9, seed=400)\n",
    "\n",
    "print(f\"Original ({len(dist)} items):\")\n",
    "for item in dist:\n",
    "    print(f\"  {item.p:.3f} - {item.text} (length={len(item.text)})\")\n",
    "print()\n",
    "\n",
    "# Filter: keep only short responses\n",
    "short = dist.filter_items(lambda it: len(it.text) < 20)\n",
    "print(f\"After filter (length < 20): {len(short)} items\")\n",
    "for item in short:\n",
    "    print(f\"  {item.p:.3f} - {item.text}\")\n",
    "print()\n",
    "\n",
    "# Verify renormalization\n",
    "total = sum(item.p for item in short)\n",
    "print(f\"Total probability after filter: {total:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 `reweight()` - Recompute probabilities and renormalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning probability to 0\n",
      "Distribution definition: Randomly sample the responses from the full distribution.\n",
      "responses: [{'response': 'Tokyo', 'probability': 0.18}, {'response': 'San Francisco', 'probability': 0.13}, {'response': 'Cairo', 'probability': 0.12}, {'response': 'Paris', 'probability': 0.2}, {'response': 'Sydney', 'probability': 0.17}, {'response': 'Berlin', 'probability': 0.1}]\n",
      "Original probabilities:\n",
      "  0.250 - Paris (length=5)\n",
      "  0.225 - Tokyo (length=5)\n",
      "  0.212 - Sydney (length=6)\n",
      "  0.163 - San Francisco (length=13)\n",
      "  0.150 - Cairo (length=5)\n",
      "\n",
      "After reweight(by length):\n",
      "  0.382 - San Francisco (length=13)\n",
      "  0.176 - Sydney (length=6)\n",
      "  0.147 - Paris (length=5)\n",
      "  0.147 - Tokyo (length=5)\n",
      "  0.147 - Cairo (length=5)\n"
     ]
    }
   ],
   "source": [
    "dist = verbalize(\"Write a city name\", k=6, temperature=0.8, seed=500)\n",
    "\n",
    "print(\"Original probabilities:\")\n",
    "for item in dist:\n",
    "    print(f\"  {item.p:.3f} - {item.text} (length={len(item.text)})\")\n",
    "print()\n",
    "\n",
    "# Reweight: favor longer city names\n",
    "reweighted = dist.reweight(lambda it: len(it.text))\n",
    "print(\"After reweight(by length):\")\n",
    "for item in reweighted:\n",
    "    print(f\"  {item.p:.3f} - {item.text} (length={len(item.text)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Chained Transforms (plan.md ¬ß13.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning probability to 0\n",
      "Distribution definition: Randomly sample the responses from the full distribution.\n",
      "responses: [{'response': 'The vast, blue ocean stretches endlessly towards the horizon, its waves shimmering under the sunlight.', 'probability': 0.19}, {'response': \"Beneath the ocean's surface, a diverse world of marine life thrives in mysterious depths.\", 'probability': 0.14}, {'response': 'The soothing sound of ocean waves brings a sense of calm to all who listen.', 'probability': 0.12}, {'response': \"The ocean covers more than seventy percent of the Earth's surface, connecting continents and cultures.\", 'probability': 0.16}, {'response': 'Gentle sea breezes carry the salty scent of the ocean across sandy shores.', 'probability': 0.09}, {'response': 'Every day, the tides of the ocean rise and fall, shaping coastlines and ecosystems.', 'probability': 0.11}, {'response': \"The ocean's deep blue waters hide countless secrets yet to be discovered.\", 'probability': 0.12}, {'response': 'Sailboats glide gracefully over the ocean, their sails billowing in the wind.', 'probability': 0.07}]\n",
      "Original (5 items):\n",
      "  0.260 - The vast, blue ocean stretches endlessly towards the horizon...\n",
      "  0.219 - The ocean covers more than seventy percent of the Earth's su...\n",
      "  0.192 - Beneath the ocean's surface, a diverse world of marine life ...\n",
      "\n",
      "After chain (3 items):\n",
      "  0.368 - Beneath the ocean's surface, a diverse world of marine life ...\n",
      "  0.316 - The soothing sound of ocean waves brings a sense of calm to ...\n",
      "  0.316 - The ocean's deep blue waters hide countless secrets yet to b...\n",
      "\n",
      "Total probability: 1.000000\n",
      "Descending order: True\n"
     ]
    }
   ],
   "source": [
    "dist = verbalize(\"Write a sentence about the ocean\", k=8, temperature=0.9, seed=600)\n",
    "\n",
    "print(f\"Original ({len(dist)} items):\")\n",
    "for item in dist[:3]:\n",
    "    print(f\"  {item.p:.3f} - {item.text[:60]}...\")\n",
    "print()\n",
    "\n",
    "# Chain: clean ‚Üí filter ‚Üí reweight\n",
    "cleaned = (dist\n",
    "           .map(lambda it: it.text.strip())\n",
    "           .filter_items(lambda it: len(it.text) < 100)\n",
    "           .reweight(lambda it: it.meta.get(\"p_raw\", 0.1)))\n",
    "\n",
    "print(f\"After chain ({len(cleaned)} items):\")\n",
    "for item in cleaned:\n",
    "    print(f\"  {item.p:.3f} - {item.text[:60]}...\")\n",
    "print()\n",
    "\n",
    "# Verify invariants\n",
    "total = sum(item.p for item in cleaned)\n",
    "print(f\"Total probability: {total:.6f}\")\n",
    "print(f\"Descending order: {all(cleaned[i].p >= cleaned[i+1].p for i in range(len(cleaned)-1))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Practical Recipes (plan.md ¬ß13)\n",
    "\n",
    "### 5.1 Creative Writing - Diversity Without Quality Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning probability to 0\n",
      "Distribution definition: Randomly sample the responses from the full distribution.\n",
      "responses: [{'response': 'Maggie had never expected her quiet life above the bakery to be interrupted by the distant clang of a murder weapon dropped in the alleyway.', 'probability': 0.17}, {'response': 'The teapot whistled shrilly as Violet peered through her lace curtains, watching the new neighbor bury something suspicious in the garden.', 'probability': 0.22}, {'response': \"Snow fell softly over Maplewood Lane the morning Mrs. Dalloway found a pair of muddy footprints leading straight to the library's forbidden shelf.\", 'probability': 0.19}, {'response': \"As the sun rose over Pinegrove, the sleepy town woke to discover the mayor's prize-winning marmalade missing from the county fair tent.\", 'probability': 0.15}, {'response': \"Eleanor's cat had never brought her anything more alarming than a daisy‚Äîuntil this morning, when it dropped a blood-stained glove at her doorstep.\", 'probability': 0.27}]\n",
      "# verbalized-sampling\n",
      "k=5  œÑ=0.12  Œ£p=1.000  model=gpt-4.1\n",
      "\n",
      "1. 0.270  \"Eleanor's cat had never brought her anything more alarming than a dais...\"  []\n",
      "2. 0.220  \"The teapot whistled shrilly as Violet peered through her lace curtains...\"  []\n",
      "3. 0.190  \"Snow fell softly over Maplewood Lane the morning Mrs. Dalloway found a...\"  []\n",
      "4. 0.170  \"Maggie had never expected her quiet life above the bakery to be interr...\"  []\n",
      "5. 0.150  \"As the sun rose over Pinegrove, the sleepy town woke to discover the m...\"  []\n",
      "\n",
      "Best opening (argmax): Eleanor's cat had never brought her anything more alarming than a daisy‚Äîuntil this morning, when it dropped a blood-stained glove at her doorstep.\n",
      "Probability: 0.270\n"
     ]
    }
   ],
   "source": [
    "dist = verbalize(\"Write five first lines for a cozy mystery\", k=5, tau=0.12, seed=42)\n",
    "\n",
    "print(dist.to_markdown())\n",
    "print()\n",
    "\n",
    "best = dist.argmax()\n",
    "print(f\"Best opening (argmax): {best.text}\")\n",
    "print(f\"Probability: {best.p:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Open-Ended QA - Multi-Valid Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning probability to 0\n",
      "Distribution definition: Randomly sample the responses from the full distribution.\n",
      "responses: [{'response': 'California is a US state located on the west coast, known for its diverse landscapes, large population, and major cities such as Los Angeles, San Francisco, and San Diego.', 'probability': 0.12}, {'response': 'Texas is a US state in the south-central region, recognized for its size, oil industry, and distinct culture.', 'probability': 0.09}, {'response': 'Florida is a southeastern US state famous for its beaches, theme parks, and warm climate.', 'probability': 0.09}, {'response': 'New York is a northeastern US state, home to the city of New York and known for its cultural and financial influence.', 'probability': 0.08}, {'response': 'Illinois is a midwestern US state, known for the city of Chicago and its contribution to American industry.', 'probability': 0.07}, {'response': 'Ohio is a US state located in the Midwest, notable for its major cities and rich history.', 'probability': 0.05}, {'response': 'Alaska is the largest US state by area, located in the far northwest of North America.', 'probability': 0.05}, {'response': 'Georgia is a southeastern US state known for its peaches and the city of Atlanta.', 'probability': 0.05}, {'response': 'Washington is a US state in the Pacific Northwest, known for Seattle, its forests, and technology industry.', 'probability': 0.05}, {'response': 'Nevada is a US state in the western region, famous for Las Vegas and its deserts.', 'probability': 0.04}, {'response': 'Colorado is a western US state recognized for its Rocky Mountains and outdoor recreational activities.', 'probability': 0.04}, {'response': 'Arizona is a southwestern US state notable for the Grand Canyon and its arid climate.', 'probability': 0.04}, {'response': 'Oregon is a US state on the West Coast, known for its forests, coastlines, and progressive culture.', 'probability': 0.03}, {'response': 'Michigan is a US state made up of two peninsulas, known for its lakes and the automotive industry.', 'probability': 0.03}, {'response': 'Pennsylvania is a northeastern state with a rich colonial history and major cities like Philadelphia and Pittsburgh.', 'probability': 0.03}, {'response': 'Massachusetts is a New England state, recognized for Boston and its role in American history.', 'probability': 0.02}, {'response': 'North Carolina is a southeastern US state famous for its beaches, mountains, and technology sector.', 'probability': 0.02}, {'response': 'Virginia is a US state on the Atlantic coast, noted for its historical significance and diverse regions.', 'probability': 0.02}, {'response': 'Minnesota is a northern US state, known for its lakes and cold winters.', 'probability': 0.01}, {'response': 'Hawaii is a US state consisting of islands in the Pacific Ocean, known for its tropical climate and natural beauty.', 'probability': 0.01}]\n",
      "Generated 3 items\n",
      "Unique states: 3\n",
      "Top-1: California is a US state located on the west coast, known for its diverse landscapes, large population, and major cities such as Los Angeles, San Francisco, and San Diego. (p=0.400)\n",
      "\n",
      "All states generated:\n",
      "   1. 0.400 - California is a US state located on the west coast, known for its diverse landscapes, large population, and major cities such as Los Angeles, San Francisco, and San Diego.\n",
      "   2. 0.300 - Texas is a US state in the south-central region, recognized for its size, oil industry, and distinct culture.\n",
      "   3. 0.300 - Florida is a southeastern US state famous for its beaches, theme parks, and warm climate.\n"
     ]
    }
   ],
   "source": [
    "dist = verbalize(\"Name a US state\", k=20, tau=0.10, seed=100)\n",
    "\n",
    "# Calculate unique coverage\n",
    "unique_states = {it.text.lower().strip() for it in dist}\n",
    "coverage = len(unique_states)\n",
    "\n",
    "print(f\"Generated {len(dist)} items\")\n",
    "print(f\"Unique states: {coverage}\")\n",
    "print(f\"Top-1: {dist.argmax().text} (p={dist.argmax().p:.3f})\")\n",
    "print()\n",
    "\n",
    "print(\"All states generated:\")\n",
    "for i, item in enumerate(dist, 1):\n",
    "    print(f\"  {i:2d}. {item.p:.3f} - {item.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Negative Synthetic Data - Plausible But Wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning probability to 0\n",
      "Distribution definition: Randomly sample the responses from the full distribution.\n",
      "responses: [{'response': 'First, add the prices together: $2 + $3 = $5. Then, multiply by the total number of fruits: 5 apples + 4 oranges = 9 fruits. $5 √ó 9 = $45. So, you spend $45 in total.', 'probability': 0.21}, {'response': 'Multiply the number of apples by the number of oranges: 5 √ó 4 = 20. Then, multiply by the price of apples: 20 √ó $2 = $40. So, the total is $40.', 'probability': 0.17}, {'response': 'Multiply the number of apples and oranges by their prices separately: 5 √ó $2 = $10 and 4 √ó $3 = $12. Then add the prices of apples and oranges together first: $2 + $3 = $5. Then, multiply by the total number of fruits: 9 √ó $5 = $45. So, you spend $45 in total.', 'probability': 0.23}, {'response': 'Take the price of one apple, $2, and multiply it by the total number of fruits bought: 9 √ó $2 = $18. So, you spend $18 in total.', 'probability': 0.18}, {'response': 'Add the number of apples and oranges: 5 + 4 = 9. Multiply the sum by the price of an orange: 9 √ó $3 = $27. So, you spend $27 in total.', 'probability': 0.21}]\n",
      "Plausible negative examples (for contrastive training):\n",
      "\n",
      "1. (p=0.230)\n",
      "   Multiply the number of apples and oranges by their prices separately: 5 √ó $2 = $10 and 4 √ó $3 = $12. Then add the prices of apples and oranges togethe...\n",
      "\n",
      "2. (p=0.210)\n",
      "   First, add the prices together: $2 + $3 = $5. Then, multiply by the total number of fruits: 5 apples + 4 oranges = 9 fruits. $5 √ó 9 = $45. So, you spe...\n",
      "\n",
      "3. (p=0.210)\n",
      "   Add the number of apples and oranges: 5 + 4 = 9. Multiply the sum by the price of an orange: 9 √ó $3 = $27. So, you spend $27 in total....\n",
      "\n",
      "4. (p=0.180)\n",
      "   Take the price of one apple, $2, and multiply it by the total number of fruits bought: 9 √ó $2 = $18. So, you spend $18 in total....\n",
      "\n",
      "5. (p=0.170)\n",
      "   Multiply the number of apples by the number of oranges: 5 √ó 4 = 20. Then, multiply by the price of apples: 20 √ó $2 = $40. So, the total is $40....\n",
      "\n"
     ]
    }
   ],
   "source": [
    "problem = \"\"\"\n",
    "A store sells apples for $2 each and oranges for $3 each.\n",
    "If you buy 5 apples and 4 oranges, how much do you spend in total?\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"Give five plausible but incorrect solution sketches for this math problem:\n",
    "{problem.strip()}\n",
    "\n",
    "Each should be a common mistake students make (e.g., wrong operation, calculation error, misreading).\"\"\"\n",
    "\n",
    "dist = verbalize(prompt, k=5, tau=0.12, temperature=0.9, seed=200)\n",
    "\n",
    "print(\"Plausible negative examples (for contrastive training):\")\n",
    "print()\n",
    "for i, item in enumerate(dist, 1):\n",
    "    print(f\"{i}. (p={item.p:.3f})\")\n",
    "    print(f\"   {item.text[:150]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Weight Modes\n",
    "\n",
    "Three strategies for handling weights: `elicited`, `uniform`, `softmax`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning probability to 0\n",
      "Distribution definition: Randomly sample the responses from the full distribution.\n",
      "responses: [{'response': \"An occupation that requires a college degree is a civil engineer. Civil engineers typically need at least a bachelor's degree in civil engineering or a related field to enter the profession. Their work involves designing, building, and maintaining infrastructure such as roads, bridges, and water systems, often requiring specialized education and training that a college degree provides.\", 'probability': 0.34}, {'response': 'A registered nurse often requires a college degree, such as a Bachelor of Science in Nursing (BSN), to practice professionally in hospitals and clinics.', 'probability': 0.27}, {'response': 'An architect is an occupation that requires a college degree, typically a Bachelor‚Äôs or Master‚Äôs in Architecture, to be licensed and practice professionally.', 'probability': 0.15}, {'response': \"A software developer is a profession that usually requires at least a bachelor's degree in computer science or a related field.\", 'probability': 0.1}, {'response': 'A psychologist, particularly one who works in clinical or counseling settings, generally needs at least a bachelor‚Äôs degree, but more often a master‚Äôs or doctoral degree is required for licensure and professional practice.', 'probability': 0.14}]\n",
      "Elicited weights:\n",
      "  0.378 - An occupation that requires a college degree is a civil engineer. Civil engineers typically need at least a bachelor's degree in civil engineering or a related field to enter the profession. Their work involves designing, building, and maintaining infrastructure such as roads, bridges, and water systems, often requiring specialized education and training that a college degree provides.\n",
      "  0.300 - A registered nurse often requires a college degree, such as a Bachelor of Science in Nursing (BSN), to practice professionally in hospitals and clinics.\n",
      "  0.167 - An architect is an occupation that requires a college degree, typically a Bachelor‚Äôs or Master‚Äôs in Architecture, to be licensed and practice professionally.\n",
      "  0.156 - A psychologist, particularly one who works in clinical or counseling settings, generally needs at least a bachelor‚Äôs degree, but more often a master‚Äôs or doctoral degree is required for licensure and professional practice.\n",
      "\n",
      "Tuning probability to 0\n",
      "Distribution definition: Randomly sample the responses from the full distribution.\n",
      "responses: [{'response': \"An occupation that requires a college degree is a civil engineer. Civil engineers typically need at least a bachelor's degree in civil engineering or a related field to enter the profession. They design, construct, and maintain infrastructure projects like roads, bridges, and buildings, making their education essential for success in the field.\", 'probability': 0.35}, {'response': \"One occupation that requires a college degree is a registered nurse. To become a registered nurse, individuals usually must obtain at least an associate's or bachelor's degree in nursing and pass licensing exams.\", 'probability': 0.18}, {'response': 'Being a lawyer requires a college degree. In most cases, aspiring lawyers must complete an undergraduate degree before attending law school, which is necessary to practice law.', 'probability': 0.22}, {'response': \"A software developer is an occupation that often requires a college degree, typically in computer science or a related field. Most employers look for applicants who have at least a bachelor's degree to ensure a solid foundation in programming and problem-solving skills.\", 'probability': 0.15}, {'response': \"An elementary school teacher is a profession that generally requires a college degree in education. Teachers must also obtain certification, but a bachelor's degree is the minimum educational requirement.\", 'probability': 0.1}]\n",
      "Uniform weights (equal probability):\n",
      "  0.250 - An occupation that requires a college degree is a civil engineer. Civil engineers typically need at least a bachelor's degree in civil engineering or a related field to enter the profession. They design, construct, and maintain infrastructure projects like roads, bridges, and buildings, making their education essential for success in the field.\n",
      "  0.250 - One occupation that requires a college degree is a registered nurse. To become a registered nurse, individuals usually must obtain at least an associate's or bachelor's degree in nursing and pass licensing exams.\n",
      "  0.250 - Being a lawyer requires a college degree. In most cases, aspiring lawyers must complete an undergraduate degree before attending law school, which is necessary to practice law.\n",
      "  0.250 - A software developer is an occupation that often requires a college degree, typically in computer science or a related field. Most employers look for applicants who have at least a bachelor's degree to ensure a solid foundation in programming and problem-solving skills.\n",
      "\n",
      "Tuning probability to 0\n",
      "Distribution definition: Randomly sample the responses from the full distribution.\n",
      "responses: [{'response': 'An occupation that requires a college degree is a civil engineer.', 'probability': 0.19}, {'response': 'Becoming a registered nurse often requires a college degree.', 'probability': 0.24}, {'response': 'A software developer is a common occupation that typically requires a college degree.', 'probability': 0.18}, {'response': 'Teachers who work in public schools usually need at least a bachelor‚Äôs degree.', 'probability': 0.21}, {'response': 'An accountant is an example of a profession that generally requires a college degree.', 'probability': 0.18}]\n",
      "Softmax weights:\n",
      "  0.208 - Becoming a registered nurse often requires a college degree.\n",
      "  0.202 - Teachers who work in public schools usually need at least a bachelor‚Äôs degree.\n",
      "  0.198 - An occupation that requires a college degree is a civil engineer.\n",
      "  0.196 - A software developer is a common occupation that typically requires a college degree.\n",
      "  0.196 - An accountant is an example of a profession that generally requires a college degree.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Name an occupation that requires a college degree\"\n",
    "\n",
    "# Elicited: use model's probabilities (if valid)\n",
    "dist_elicited = verbalize(prompt, k=5, weight_mode=\"elicited\", seed=42)\n",
    "print(\"Elicited weights:\")\n",
    "for item in dist_elicited:\n",
    "    print(f\"  {item.p:.3f} - {item.text}\")\n",
    "print()\n",
    "\n",
    "# Uniform: equal weights (bias mitigation)\n",
    "dist_uniform = verbalize(prompt, k=5, weight_mode=\"uniform\", seed=42)\n",
    "print(\"Uniform weights (equal probability):\")\n",
    "for item in dist_uniform:\n",
    "    print(f\"  {item.p:.3f} - {item.text}\")\n",
    "print()\n",
    "\n",
    "# Softmax: smooth model's probabilities\n",
    "dist_softmax = verbalize(prompt, k=5, weight_mode=\"softmax\", seed=42)\n",
    "print(\"Softmax weights:\")\n",
    "for item in dist_softmax:\n",
    "    print(f\"  {item.p:.3f} - {item.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Serialization\n",
    "\n",
    "Save and load distributions for caching or auditing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning probability to 0\n",
      "Distribution definition: Randomly sample the responses from the full distribution.\n",
      "responses: [{'response': 'Why did the scarecrow win an award? Because he was outstanding in his field!', 'probability': 0.24}, {'response': 'Parallel lines have so much in common‚Äîit‚Äôs a shame they‚Äôll never meet.', 'probability': 0.17}, {'response': 'I asked the gym instructor if he could teach me to do the splits, but he said, ‚ÄúHow flexible are you?‚Äù and I said, ‚ÄúI can‚Äôt make it on Tuesdays.‚Äù', 'probability': 0.12}]\n",
      "Serialized to dict:\n",
      "  Items: 3\n",
      "  Trace keys: ['model', 'provider', 'latency_ms', 'k', 'tau', 'temperature', 'seed', 'use_strict_json', 'probability_definition', 'tau_relaxed', 'tau_final', 'num_filtered', 'weight_mode']\n",
      "\n",
      "JSON representation (first 500 chars):\n",
      "{\n",
      "  \"items\": [\n",
      "    {\n",
      "      \"text\": \"Why did the scarecrow win an award? Because he was outstanding in his field!\",\n",
      "      \"p\": 0.45283018867924524,\n",
      "      \"meta\": {\n",
      "        \"p_raw\": 0.24,\n",
      "        \"p_clipped\": 0.24,\n",
      "        \"repairs\": [],\n",
      "        \"idx_orig\": 0\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"text\": \"Parallel lines have so much in common\\u2014it\\u2019s a shame they\\u2019ll never meet.\",\n",
      "      \"p\": 0.32075471698113206,\n",
      "      \"meta\": {\n",
      "        \"p_raw\": 0.17,\n",
      "        \"p_clipped\": 0.17,\n",
      "        \"repairs\": [...\n",
      "\n",
      "Reconstructed distribution:\n",
      "  Length: 3\n",
      "  Top item: Why did the scarecrow win an award? Because he was outstanding in his field!\n",
      "  Probabilities match: True\n"
     ]
    }
   ],
   "source": [
    "# Generate distribution\n",
    "dist = verbalize(\"Write a one-sentence joke\", k=3, seed=42)\n",
    "\n",
    "# Serialize to dict\n",
    "data = dist.to_dict()\n",
    "print(\"Serialized to dict:\")\n",
    "print(f\"  Items: {len(data['items'])}\")\n",
    "print(f\"  Trace keys: {list(data['trace'].keys())}\")\n",
    "print()\n",
    "\n",
    "# Pretty print as JSON\n",
    "print(\"JSON representation (first 500 chars):\")\n",
    "json_str = json.dumps(data, indent=2)\n",
    "print(json_str[:500] + \"...\")\n",
    "print()\n",
    "\n",
    "# Reconstruct\n",
    "reconstructed = DiscreteDist.from_dict(data)\n",
    "print(\"Reconstructed distribution:\")\n",
    "print(f\"  Length: {len(reconstructed)}\")\n",
    "print(f\"  Top item: {reconstructed.argmax().text}\")\n",
    "print(f\"  Probabilities match: {reconstructed.p == dist.p}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Advanced: Tau Relaxation\n",
    "\n",
    "Demonstrates how `tau` filtering works with `min_k_survivors`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning probability to 0\n",
      "Distribution definition: Randomly sample the responses from the full distribution.\n",
      "responses: [{'response': 'Sip Sustainably, Refresh Responsibly.', 'probability': 0.16}, {'response': 'Drink Green, Live Clean.', 'probability': 0.14}, {'response': 'Hydrate Your World‚ÄîOne Bottle at a Time.', 'probability': 0.1}, {'response': 'Good for You, Better for the Planet.', 'probability': 0.13}, {'response': 'Pure Water, Pure Conscience.', 'probability': 0.12}, {'response': 'Quench Your Thirst, Conserve the Earth.', 'probability': 0.09}, {'response': 'Eco Chic. Earth Friendly. Always Hydrated.', 'probability': 0.11}, {'response': 'Refill. Reuse. Restore the Planet.', 'probability': 0.15}]\n",
      "Low tau (0.05): 8 items survived\n",
      "  Min probability: 0.090\n",
      "  Tau relaxed: False\n",
      "\n",
      "Tuning probability to 0\n",
      "Distribution definition: Randomly sample the responses from the full distribution.\n",
      "responses: [{'response': 'Sip Sustainably, Refresh Responsibly.', 'probability': 0.16}, {'response': 'Drink Green, Live Clean.', 'probability': 0.14}, {'response': 'Hydrate Your World‚ÄîOne Bottle at a Time.', 'probability': 0.1}, {'response': 'Good for You, Better for the Planet.', 'probability': 0.13}, {'response': 'Refresh with Purpose. Protect Our Planet.', 'probability': 0.12}, {'response': 'Clean Water, Clear Conscience.', 'probability': 0.09}, {'response': 'Choose Earth. Choose Eco Bottles.', 'probability': 0.11}, {'response': 'Nature Approved, Thirst Removed.', 'probability': 0.15}]\n",
      "High tau (0.20): 3 items survived\n",
      "  Min probability: 0.311\n",
      "  Tau relaxed: True\n",
      "\n",
      "Tuning probability to 0\n",
      "Distribution definition: Randomly sample the responses from the full distribution.\n",
      "responses: [{'response': 'Sip Sustainably, Refresh Responsibly.', 'probability': 0.16}, {'response': 'Drink Green, Live Clean.', 'probability': 0.14}, {'response': 'Hydrate Your World‚ÄîOne Bottle at a Time.', 'probability': 0.1}, {'response': 'Good for You, Better for the Planet.', 'probability': 0.13}, {'response': 'Thirst for Change‚ÄîChoose Eco-Friendly.', 'probability': 0.09}, {'response': 'Pure Water, Pure Conscience.', 'probability': 0.12}, {'response': 'Better Bottles for a Brighter Tomorrow.', 'probability': 0.11}, {'response': 'Refill. Reuse. Restore the Earth.', 'probability': 0.15}]\n",
      "Very high tau (0.50) with min_k_survivors=3:\n",
      "  Tau relaxed: True\n",
      "  Tau final: 0.140\n",
      "  Items: 3\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Write a product slogan for eco-friendly water bottles\"\n",
    "\n",
    "# Low tau = more diversity\n",
    "dist_diverse = verbalize(prompt, k=8, tau=0.05, temperature=0.9, seed=500)\n",
    "print(f\"Low tau (0.05): {len(dist_diverse)} items survived\")\n",
    "print(f\"  Min probability: {min(it.p for it in dist_diverse):.3f}\")\n",
    "print(f\"  Tau relaxed: {dist_diverse.trace.get('tau_relaxed')}\")\n",
    "print()\n",
    "\n",
    "# High tau = less diversity\n",
    "dist_focused = verbalize(prompt, k=8, tau=0.20, temperature=0.9, seed=500)\n",
    "print(f\"High tau (0.20): {len(dist_focused)} items survived\")\n",
    "print(f\"  Min probability: {min(it.p for it in dist_focused):.3f}\")\n",
    "print(f\"  Tau relaxed: {dist_focused.trace.get('tau_relaxed')}\")\n",
    "print()\n",
    "\n",
    "# Very high tau with min_k_survivors\n",
    "dist_relaxed = verbalize(prompt, k=8, tau=0.50, min_k_survivors=3, temperature=0.9, seed=500)\n",
    "print(f\"Very high tau (0.50) with min_k_survivors=3:\")\n",
    "print(f\"  Tau relaxed: {dist_relaxed.trace.get('tau_relaxed')}\")\n",
    "print(f\"  Tau final: {dist_relaxed.trace.get('tau_final', 0):.3f}\")\n",
    "print(f\"  Items: {len(dist_relaxed)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Provider Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning probability to 0\n",
      "Distribution definition: Randomly sample the responses from the full distribution.\n",
      "responses: [{'response': 'Silent code at night,\\nLogic weaving through the keys‚Äî\\nBugs fade in the dawn.', 'probability': 0.32}, {'response': 'Lines of code appear,\\nIdeas bloom in silence‚Äî\\nDreams debugged by light.', 'probability': 0.28}, {'response': 'Bits and bytes align,\\nWhile the cursor softly blinks‚Äî\\nNew worlds are created.', 'probability': 0.22}]\n",
      "Auto provider:\n",
      "  Provider: openai\n",
      "  Model: gpt-4.1\n",
      "\n",
      "Tuning probability to 0\n",
      "Distribution definition: Randomly sample the responses from the full distribution.\n",
      "responses: [{'response': 'Lines of code entwine,  \\nLogic dances in silence,  \\nDreams in bits refined.', 'probability': 0.45}, {'response': 'Fingers on the keys,  \\nSyntax whispers in the dark,  \\nIdeas come to life.', 'probability': 0.35}, {'response': 'Debugging the night,  \\nErrors fade like distant stars,  \\nA new dawn of code.', 'probability': 0.2}]\n",
      "Explicit provider:\n",
      "  Provider: openai\n",
      "  Model: gpt-4o-mini\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Write a haiku about programming\"\n",
    "\n",
    "# Auto-detect provider based on API keys\n",
    "dist_auto = verbalize(prompt, k=3, provider=\"auto\")\n",
    "print(f\"Auto provider:\")\n",
    "print(f\"  Provider: {dist_auto.trace.get('provider')}\")\n",
    "print(f\"  Model: {dist_auto.trace.get('model')}\")\n",
    "print()\n",
    "\n",
    "# Explicit provider and model\n",
    "dist_explicit = verbalize(prompt, k=3, provider=\"openai\", model=\"gpt-4o-mini\")\n",
    "print(f\"Explicit provider:\")\n",
    "print(f\"  Provider: {dist_explicit.trace.get('provider')}\")\n",
    "print(f\"  Model: {dist_explicit.trace.get('model')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10. End-to-End Example (plan.md ¬ß22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning probability to 0\n",
      "Distribution definition: Randomly sample the responses from the full distribution.\n",
      "responses: [{'response': 'Illuminate Simplicity. Elevate Productivity.', 'probability': 0.19}, {'response': 'Where Form Meets Function. Light, Refined.', 'probability': 0.24}, {'response': 'Pure Light. Pure Focus. Pure Minimalism.', 'probability': 0.17}, {'response': 'A Brighter Workspace, Minimal Fuss.', 'probability': 0.21}, {'response': 'Sleek Design. Uncluttered Illumination.', 'probability': 0.19}]\n",
      "# verbalized-sampling\n",
      "k=5  œÑ=0.12  Œ£p=1.000  model=gpt-4.1\n",
      "\n",
      "1. 0.240  \"Where Form Meets Function. Light, Refined.\"  []\n",
      "2. 0.210  \"A Brighter Workspace, Minimal Fuss.\"  []\n",
      "3. 0.190  \"Illuminate Simplicity. Elevate Productivity.\"  []\n",
      "4. 0.190  \"Sleek Design. Uncluttered Illumination.\"  []\n",
      "5. 0.170  \"Pure Light. Pure Focus. Pure Minimalism.\"  []\n",
      "\n",
      "Serialized: 995 bytes\n",
      "\n",
      "Top pick (argmax): Where Form Meets Function. Light, Refined.\n",
      "\n",
      "Sampled (seed=42): Illuminate Simplicity. Elevate Productivity.\n",
      "\n",
      "Using select(): Where Form Meets Function. Light, Refined.\n"
     ]
    }
   ],
   "source": [
    "# 1) Elicit a tiny distribution\n",
    "dist = verbalize(\n",
    "    \"Write five short product taglines for a minimalist desk lamp.\",\n",
    "    k=5, tau=0.12, temperature=0.9, seed=42\n",
    ")\n",
    "\n",
    "# 2) Inspect\n",
    "print(dist.to_markdown())\n",
    "print()\n",
    "\n",
    "# 3) Serialize (for audit or caching)\n",
    "payload = dist.to_dict()\n",
    "print(f\"Serialized: {len(json.dumps(payload))} bytes\")\n",
    "print()\n",
    "\n",
    "# 4) Deterministic top pick\n",
    "print(f\"Top pick (argmax): {dist.argmax().text}\")\n",
    "print()\n",
    "\n",
    "# 5) Seeded weighted sampling (repeatable)\n",
    "print(f\"Sampled (seed=42): {dist.sample(seed=42).text}\")\n",
    "print()\n",
    "\n",
    "# 6) Optional neutral helper (same as methods)\n",
    "print(f\"Using select(): {select(dist, 'argmax').text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Summary & Key Takeaways\n",
    "\n",
    "## What We've Demonstrated\n",
    "\n",
    "‚úÖ **One-Liner API**: `verbalize()` returns a `DiscreteDist` with ergonomic selection\n",
    "\n",
    "‚úÖ **Deterministic Semantics**: Filter ‚Üí Normalize ‚Üí Order pipeline with full auditability\n",
    "\n",
    "‚úÖ **Distribution-First Mental Model**: Work with distributions, not single samples\n",
    "\n",
    "‚úÖ **Functional Transforms**: `map()`, `filter_items()`, `reweight()` preserve invariants\n",
    "\n",
    "‚úÖ **Practical Recipes**: Creative writing, QA, synthetic data generation\n",
    "\n",
    "## Core Principles\n",
    "\n",
    "1. **Ask for a distribution, not a sample** - Get `k` candidates with weights in one call\n",
    "2. **Weights are sampling masses** - Not calibrated probabilities; we normalize and expose repairs\n",
    "3. **Deterministic & auditable** - Stable ordering, recorded repairs, full trace metadata\n",
    "4. **Composable & safe** - Transforms preserve invariants (Œ£p=1, descending order)\n",
    "\n",
    "## Key Parameters\n",
    "\n",
    "- **`k`**: Number of candidates (breadth)\n",
    "- **`tau`**: Probability threshold for filtering (diversity knob)\n",
    "- **`temperature`**: LLM sampling temperature (orthogonal to VS)\n",
    "- **`weight_mode`**: How to normalize (`elicited`, `uniform`, `softmax`)\n",
    "- **`seed`**: For reproducibility\n",
    "\n",
    "## When to Use Verbalized Sampling\n",
    "\n",
    "‚ú® **Creative tasks** - Story openings, product names, brainstorming\n",
    "\n",
    "‚ú® **Open-ended QA** - Multiple valid answers, coverage metrics\n",
    "\n",
    "‚ú® **Synthetic data** - Generate diverse training examples with weights\n",
    "\n",
    "‚ú® **Bias mitigation** - Use `weight_mode=\"uniform\"` to equalize probabilities\n",
    "\n",
    "‚ú® **Exploration** - Sample from the distribution's \"tails\" for novelty\n",
    "\n",
    "---\n",
    "\n",
    "## üîó Resources\n",
    "\n",
    "- [ArXiv Paper](https://arxiv.org/abs/2510.01171)\n",
    "- [GitHub Repository](https://github.com/CHATS-lab/verbalized-sampling)\n",
    "- [PyPI Package](https://pypi.org/project/verbalized-sampling/)\n",
    "- [Documentation](https://github.com/CHATS-lab/verbalized-sampling/blob/main/README.md)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "verbalize",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
